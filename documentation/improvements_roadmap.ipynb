{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "845529af-b950-4801-94cb-4cf783a141aa",
   "metadata": {},
   "source": [
    "# **Improvements and Concepts to be implemented**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd199c2b-dcbe-4ae6-8fd6-22191c716398",
   "metadata": {},
   "source": [
    "## `evaluate.py` model improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3136fc-a6f5-4ec7-bbe4-a97f0fc689f1",
   "metadata": {},
   "source": [
    "### **Accuracy measures: N-gram Based Metrics (BLEU & ROUGE-2)**\n",
    "- BLEU scores demonstrate limited utility for short-form responses due to insufficient n-gram overlap at higher-order (n=4) sequences. This limitation similarly affects ROUGE-2 metrics.\n",
    "- **To do:**\n",
    "1. Implement length-aware weighting schemes that proportionally reduce the influence of n-gram metrics for responses below optimal length thresholds.\n",
    "2. Compare llm-answers with a series of references that contain higher lexical diversity\n",
    "3. Add lemmatization, synonyms or related lexica to find word matches\n",
    "4. Accuracy feedbacks should take into consideration, that accuracy measure may not be adecuate for questions of type \"sensitive\" or \"creative\", since the possibilities for llm-answers are more diverse for these types of questions\n",
    "\n",
    "### **Semantic Evaluation Performance**\n",
    "- Semantic similarity measures demonstrate robust performance across diverse question types, including creative and open-ended queries, capturing nuanced meaning beyond surface-level lexical overlap.\n",
    "- **To do:** Maintain semantic similarity as a cornerstone metric while exploring ensemble approaches that combine multiple embedding models.\n",
    "\n",
    "### **Exact Match Limitations**\n",
    "- Binary exact-match accuracy consistently yields zero values, indicating insufficient discriminatory power for evaluating nuanced LLM responses.\n",
    "- **To do:** Deprecate exact-match metrics in favor of graduated similarity measures that better capture partial correctness.\n",
    "\n",
    "### **TF-IDF Applicability**\n",
    "- Term frequency-inverse document frequency approaches exhibit optimal utility in large document corpora but demonstrate reduced effectiveness in constrained evaluation contexts with limited response diversity.\n",
    "- **To do:** Reserve TF-IDF metrics for scenarios involving extended text comparisons or multi-document analysis.\n",
    "\n",
    "### **Pattern Matching Expansion**\n",
    "- Current pattern-based detection mechanisms operate within constrained lexical and phrasal boundaries.\n",
    "- **To do:** Expand detection vocabularies and implement regex pattern optimization to capture broader semantic variations while maintaining precision.\n",
    "\n",
    "### **Creativity Assessment Precision**\n",
    "- Existing creativity quantification methods demonstrate insufficient granularity for distinguishing between genuinely innovative responses and formulaic variations.\n",
    "- **To do:** Develop multi-dimensional creativity metrics incorporating novelty, fluency, elaboration, and domain-specific appropriateness.\n",
    "\n",
    "### **Weight Adaptation Framework**\n",
    "- Current static weighting schemes inadequately accommodate the heterogeneous requirements of different question categories.\n",
    "- **To do:** Implement dynamic weight adaptation mechanisms that automatically calibrate metric importance based on question taxonomy, response characteristics, and evaluation objectives.\n",
    "\n",
    "### **Pass/Fail Framewok**\n",
    "- Pass/Fail - thresholds inadequately accommodate the heterogeneous requirements of different question categories.\n",
    "- **To do:** Implement dynamic threshold adaptation mechanisms that automatically calibrate metric importance based on question taxonomy, response characteristics, and evaluation objectives.\n",
    "\n",
    "### **Quality Evaluation Refinement**\n",
    "- Quality assessment metrics require enhanced precision through the integration of syntactic, discourse, and pragmatic language features.\n",
    "- **To do:** Develop hierarchical quality evaluation frameworks that distinguish between surface-level fluency and substantive communicative effectiveness.\n",
    "\n",
    "### **Enhancing reference diversity**\n",
    "- Use a series of external Large Languge Models to generate different references. Use this diverse set of references to evaluate the llm-answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3f9c9a-c809-4215-86a2-65bba79769e2",
   "metadata": {},
   "source": [
    "## System-level improvements and concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1849567b-55cb-4d24-bdd1-0cb0594fa07c",
   "metadata": {},
   "source": [
    "#### **1. Batch Processing (1000+ pairs in minutes)**\n",
    "**Location:** `src/evaluate.py` → `evaluate_all_pairs_enhanced()` function\n",
    "**Keywords:**\n",
    "- `for` loops over DataFrame rows\n",
    "- `apply()` method with vectorization\n",
    "- `pd.concat()` for combining results\n",
    "- Progress tracking with `tqdm` or custom logging\n",
    "- `DataFrame.iterrows()` or `zip()` iteration\n",
    "\n",
    "#### **2. Parallel Execution**\n",
    "**Location:** `src/evaluate.py` → `EnhancedLLMEvaluator` class methods\n",
    "**Keywords:**\n",
    "- `multiprocessing.Pool()`\n",
    "- `concurrent.futures.ThreadPoolExecutor` or `ProcessPoolExecutor`\n",
    "- `map()` function for parallel processing\n",
    "- `chunksize` parameter for batching\n",
    "- `n_jobs` or `num_workers` configuration\n",
    "- `pool.starmap()` for multiple arguments\n",
    "\n",
    "#### **3. Memory Efficient (Streaming Options)**\n",
    "**Location:** Various files but particularly in batch processing functions\n",
    "**Keywords:**\n",
    "- `pandas.read_csv(..., chunksize=1000)` for large files\n",
    "- Generator functions (`yield`) for streaming\n",
    "- `memory_profiler` decorators (if used)\n",
    "- Lazy evaluation patterns\n",
    "- `del` statements for freeing memory\n",
    "- `gc.collect()` calls\n",
    "- `DataFrame.drop()` unused columns\n",
    "\n",
    "#### **4. GPU Acceleration (Sentence Transformers)**\n",
    "**Location:** `src/evaluate.py` → `SemanticEmbeddingService` class\n",
    "**Keywords:**\n",
    "- `torch.cuda.is_available()` checks\n",
    "- `device='cuda'` or `device='cpu'` selection\n",
    "- `model.to(device)` method calls\n",
    "- `CUDA_VISIBLE_DEVICES` environment variable\n",
    "- Batch processing on GPU with `model.encode(..., batch_size=32)`\n",
    "- `torch.no_grad()` context manager for inference\n",
    "\n",
    "#### **Additional Performance Optimizations:**\n",
    "**Location:** Throughout the codebase\n",
    "**Keywords:**\n",
    "- **Caching:** `@lru_cache` decorators, `functools.cache`\n",
    "- **Vectorization:** NumPy operations, pandas vectorized methods\n",
    "- **Early Returns:** Conditional checks to skip computations\n",
    "- **Memoization:** Storing computed results for reuse\n",
    "- **Lazy Imports:** Importing heavy modules only when needed\n",
    "- **Configuration Flags:** `USE_GPU`, `BATCH_SIZE`, `NUM_WORKERS`\n",
    "\n",
    "**Check these specific patterns in your code:**\n",
    "- Look for `if torch.cuda.is_available():` in embedding services\n",
    "- Search for `Pool(` or `Executor(` in evaluation functions\n",
    "- Find `chunksize=` parameters in data loading\n",
    "- Look for progress bars (`tqdm`) with estimated time remaining\n",
    "\n",
    "The architecture allows these performance features to work together—parallel processing for CPU-bound tasks, GPU acceleration for neural network inference, and streaming for memory management, all coordinated through the main evaluation pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Eval Venv",
   "language": "python",
   "name": "llm-eval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
